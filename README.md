
# Persona Chat Engine â€“ AI NPC Dialogue System ğŸ­

[![GitHub stars](https://img.shields.io/github/stars/m97j/persona-chat-engine)](https://github.com/m97j/persona-chat-engine)


## ğŸ“Œ ê°œìš”
**Persona Chat Engine**ì€ ê²Œì„ ë‚´ NPC(Non-Player Character)ì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ AI ëŒ€í™” ì—”ì§„ì…ë‹ˆë‹¤.
ê²Œì„ í”Œë ˆì´ì–´ì˜ ì„ íƒê³¼ í–‰ë™, NPC ìƒíƒœë¥¼ ë°˜ì˜í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì™€ í€˜ìŠ¤íŠ¸ ì§„í–‰ì„ ìƒì„±í•˜ë©°, **Delta/Flag** ê¸°ë°˜ í–‰ë™ ë° ê°ì • ë³€í™”ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

* **ëª©í‘œ:** ê²Œì„ í™˜ê²½ì—ì„œ ëª°ì…ê° ìˆëŠ” AI NPC ëŒ€í™”ì™€ í€˜ìŠ¤íŠ¸ ë°˜ì‘ ìƒì„±
* **í•µì‹¬ ê¸°ìˆ :** Transformer ê¸°ë°˜ LLM, QLoRA íŒŒì¸íŠœë‹, ë©€í‹°í—¤ë“œ í•™ìŠµ(Delta/Flag), ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í¬ë§·

---

## âš™ï¸ ì•„í‚¤í…ì²˜
```mermaid
graph TD
Client[Unity Client] --input text--> GameServer[Node.js Game Server]
GameServer[Node.js Game Server] --ask ai--> AIServer[python AI Server]
AIServer[python AI Server] <--> Preprocess
AIServer[python AI Server] --prompt--> HF-Serve[HuggingFaceSpaces]
HF-Serve[HuggingFaceSpaces] --> inference
HF-Serve[HuggingFaceSpaces] --result--> AIServer[python AI Server]
AIServer[python AI Server] <--> Postprocess
AIServer[python AI Server] --npc text, deltas, flags--> GameServer[Node.js Game Server]
GameServer[Node.js Game Server] --npc text, env flags--> Client[Unity Client]
```

---

## âš™ï¸ AI ì„œë²„ (ai-server/)

### ì—­í• 

* **ê²Œì„ ì„œë²„ì™€ì˜ í†µì‹ :** í”Œë ˆì´ì–´ì˜ ë°œí™”ì™€ ìƒíƒœ ì •ë³´ë¥¼ ìˆ˜ì‹ í•˜ê³ , ëª¨ë¸ ì¶”ë¡ ì„ ìœ„í•œ ì…ë ¥ ë°ì´í„°ë¥¼ ì¤€ë¹„
* **í”„ë¡¬í”„íŠ¸ êµ¬ì„±:** ê²Œì„ ì„œë²„ë¡œë¶€í„° ë°›ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±
* **ì „ì²˜ë¦¬:** í”„ë¡¬í”„íŠ¸ì˜ í¬ë§·ì„ ëª¨ë¸ì— ë§ê²Œ ì¡°ì •í•˜ê³ , í•„ìš”í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì‚½ì…
* **í›„ì²˜ë¦¬:** ëª¨ë¸ì˜ ì¶œë ¥ì„ ê²Œì„ ì„œë²„ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜

### ì£¼ìš” ëª¨ë“ˆ

* **`dialogue_manager.py`:** ëŒ€í™” íë¦„ ê´€ë¦¬ ë° NPC ì‘ë‹µ ìƒì„±
* **`preprocess.py`:** ì…ë ¥ ë°ì´í„°ì˜ ì „ì²˜ë¦¬ ë° í”„ë¡¬í”„íŠ¸ êµ¬ì„±
* **`postprocess.py`:** ëª¨ë¸ ì¶œë ¥ì˜ í›„ì²˜ë¦¬ ë° ê²Œì„ ì„œë²„ì™€ì˜ ë°ì´í„° í¬ë§· ë³€í™˜
* **`hf_client.py`:** Hugging Face Spacesì™€ì˜ í†µì‹ ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

### ë°ì´í„° íë¦„

1. **ê²Œì„ ì„œë²„ ìš”ì²­ ìˆ˜ì‹ :** í”Œë ˆì´ì–´ì˜ ë°œí™”ì™€ ìƒíƒœ ì •ë³´ë¥¼ í¬í•¨í•œ ìš”ì²­ì„ ìˆ˜ì‹ 
2. **í”„ë¡¬í”„íŠ¸ ìƒì„±:** `preprocess.py`ë¥¼ í†µí•´ ëª¨ë¸ì— ì…ë ¥í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±
3. **ëª¨ë¸ ì¶”ë¡ :** `hf_client.py`ë¥¼ ì‚¬ìš©í•˜ì—¬ Hugging Face Spacesì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ìˆ˜ì‹ 
4. **í›„ì²˜ë¦¬:** `postprocess.py`ë¥¼ í†µí•´ ì‘ë‹µì„ ê²Œì„ ì„œë²„ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
5. **ê²Œì„ ì„œë²„ë¡œ ì‘ë‹µ ì „ì†¡:** ë³€í™˜ëœ ì‘ë‹µì„ ê²Œì„ ì„œë²„ë¡œ ì „ì†¡í•˜ì—¬ ê²Œì„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸

---

## ğŸš€ Hugging Face Spaces (hf-serve/)

### ì—­í• 

* **ëª¨ë¸ í˜¸ìŠ¤íŒ…:** Fine-tunedëœ ëª¨ë¸ê³¼ LoRA ì–´ëŒ‘í„°ë¥¼ í˜¸ìŠ¤íŒ…í•˜ì—¬ ì¶”ë¡  ì„œë¹„ìŠ¤ ì œê³µ
* **API ì—”ë“œí¬ì¸íŠ¸:** ê²Œì„ ì„œë²„ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” RESTful API ì—”ë“œí¬ì¸íŠ¸ ì œê³µ

### êµ¬ì„± ìš”ì†Œ

* **`server.py`:** FastAPIë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ RESTful API ì„œë²„ êµ¬í˜„
* **`model_utils.py`:** ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡ ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
* **`requirements.txt`:** í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ëª©ë¡

### ë°°í¬

* **Hugging Face Spaces:** `hf-serve/` ë””ë ‰í† ë¦¬ì˜ ì½”ë“œë¥¼ Hugging Face Spacesì— ë°°í¬í•˜ì—¬ API ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
* **AI ì„œë²„ í†µí•©:** AI ì„œë²„ëŠ” í•´ë‹¹ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ NPCì˜ ì‘ë‹µì„ ìˆ˜ì‹ 

---

## ğŸ“Š ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ (train/)

* Colab Notebook: [Train Model on Colab](https://colab.research.google.com/...)
* Hugging Face Model: [HF Model](https://huggingface.co/my-model)

## ğŸ›  ëª¨ë¸ ê¸°ëŠ¥

### 1. NPC ëŒ€í™” ìƒì„±

* í”Œë ˆì´ì–´ ë°œí™”(`player_utterance`)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ NPC ì‘ë‹µ ìƒì„±
* NPCì˜ ê°ì •, ì‹ ë¢°ë„, ê´€ê³„ ìƒíƒœ ë“±ì„ ë°˜ì˜
* ëŒ€í™” ë§¥ë½(`context`) ìœ ì§€

### 2. í–‰ë™ ë° ìƒíƒœ ì¶”ì 

* **Delta Head:** NPC ì‹ ë¢°(`trust`)ì™€ ê´€ê³„(`relationship`) ë³€í™” ìˆ˜ì¹˜ ì˜ˆì¸¡
* **Flag Head:** í€˜ìŠ¤íŠ¸ ì§„í–‰, ì•„ì´í…œ ì§€ê¸‰, ë©”ì¸ ìŠ¤í† ë¦¬ ì¢…ë£Œ ì—¬ë¶€ ë“± ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°

### 3. ë°ì´í„° ê¸°ë°˜ í•™ìŠµ

* JSONL ë°ì´í„° êµ¬ì¡° ê¸°ë°˜ í•™ìŠµ
**í•™ìŠµ ë°ì´í„° êµ¬ì¡°:**

* **í˜•ì‹:** JSONL
* **êµ¬ì„± ìš”ì†Œ:**

  * `npc_id`: NPC ê³ ìœ  ID
  * `tags`: ìœ„ì¹˜, ê´€ê³„ ìƒíƒœ, ì‹ ë¢°ë„, ê°ì • ìƒíƒœ ë“± íƒœê·¸ ì •ë³´
  * `context`: ì´ì „ ëŒ€í™” ë§¥ë½
  * `player_utterance`: í”Œë ˆì´ì–´ì˜ ë°œí™”
  * `response`: NPCì˜ ì‘ë‹µ
  * `delta`: ì‹ ë¢°ë„ ë° ê´€ê³„ë„ ë³€í™”ëŸ‰
  * `flag`: ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ëª©ë¡

**ì˜ˆì‹œ ë°ì´í„°:**

```json
{
  "npc_id": "mother_abandoned_factory",
  "tags": {
    "location": "abandoned_factory",
    "quest_stage": "complete",
    "relationship": "close_friend",
    "trust": 0.99,
    "npc_mood": "hopeful",
    "player_reputation": "helpful",
    "style": "somber"
  },
  "context": [
    {"role": "player", "text": "Jasonì˜ ì‚¼ì´Œì€ ì–´ë””ì— ê³„ì‹œì£ ?"},
    {"role": "npc", "text": "ì œ ë™ìƒì€ ìì‹ ì˜ ì•„ì§€íŠ¸ì— ìˆì–´ìš”..."}
  ],
  "player_utterance": "ë„¤?... ìˆ˜ìˆ˜ê»˜ë¼ ê°™ë„¤ìš”...",
  "response": "ì •ë§ ê³ ë§ˆì›Œìš”!! ì´ê±´ ìš°ë¦¬ ì§‘ì•ˆì˜ ê°€ë³´ì¸ ê¸ˆëª©ê±¸ì´ì—ìš”...",
  "delta": [0.00, 0.00],
  "flag": ["give_item", "npc_main_story"]
}
```

### 4. QLoRA ê¸°ë°˜ Fine-Tuning

### 1. ëª¨ë¸ ì•„í‚¤í…ì²˜

**Base Model:** Qwen2.5-3B-Instruct

**Adapter:** LoRA ê¸°ë°˜ 4bit Quantization Adapter

**ë©€í‹°í—¤ë“œ ì¶œë ¥ êµ¬ì¡°:**

* **Delta Head:** NPCì˜ ì‹ ë¢°ë„(trust)ì™€ ê´€ê³„ë„(relationship) ë³€í™”ë¥¼ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ ëª¨ë¸
* **Flag Head:** í€˜ìŠ¤íŠ¸ ì§„í–‰ ìƒíƒœ, ì•„ì´í…œ ì§€ê¸‰ ì—¬ë¶€ ë“± ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ëª¨ë¸

**í•™ìŠµ êµ¬ì„±:**

* **Loss í•¨ìˆ˜:**

  * **LM Loss:** ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ í•™ìŠµ ì†ì‹¤
  * **Delta Loss (MSE):** ì‹ ë¢°ë„ ë° ê´€ê³„ë„ ì˜ˆì¸¡ ì˜¤ì°¨
  * **Flag Loss (BCE):** ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ì˜ˆì¸¡ ì˜¤ì°¨

* **Trainer êµ¬í˜„:**

  * `MultiHeadTrainer` í´ë˜ìŠ¤ë¥¼ í†µí•´ ë©€í‹°í—¤ë“œ ì¶œë ¥ì„ ì²˜ë¦¬
  * ê° í—¤ë“œì˜ ì¶œë ¥ì— ëŒ€í•´ í•´ë‹¹í•˜ëŠ” ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  í•©ì‚°í•˜ì—¬ ìµœì¢… ì†ì‹¤ì„ ë„ì¶œ

```python
class MultiHeadTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.pop("labels")
        delta = inputs.pop("delta")
        flag = inputs.pop("flag")
        outputs = model(**inputs, output_hidden_states=True)
        last_hidden = outputs.hidden_states[-1][:, -1, :]
        lm_loss = nn.CrossEntropyLoss(ignore_index=-100)(outputs.logits.view(-1, outputs.logits.size(-1)), labels.view(-1))
        delta_pred = model.delta_head(last_hidden)
        mse_loss = nn.MSELoss()(delta_pred, delta)
        flag_pred = model.flag_head(last_hidden)
        bce_loss = nn.BCEWithLogitsLoss()(flag_pred, flag)
        return lm_loss + mse_loss + bce_loss
```
---

## ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡°
```

persona-chat-engine/
â”‚
â”œâ”€â”€ ai-server/        # ëŒ€í™” íŒŒì´í”„ë¼ì¸ ê´€ë¦¬, ê²Œì„ ì„œë²„ì™€ í†µì‹ 
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ agent_manager.py
â”‚   â”œâ”€â”€ dialogue_manager.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ postprocess.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ rag.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ hf_client.py
â”‚   â”‚   â””â”€â”€ model_loader.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ hf-serve/         # Hugging Face ëª¨ë¸ ì¶”ë¡  API
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ train/            # (ì˜µì…˜) ëª¨ë¸ í•™ìŠµ ê´€ë ¨ ìë£Œ
â”‚   â”œâ”€â”€ README.md     # Colab í•™ìŠµ ë§í¬
â”‚   â””â”€â”€ dataset/      # (ì˜µì…˜) json ë°ì´í„° ìƒ˜í”Œ
â”‚
â””â”€â”€ docker-compose.yml
```

---

## ğŸ“¦ ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
git clone https://github.com/m97j/persona-chat-engine.git
cd persona-chat-engine
pip install -r requirements.txt
```

### ëª¨ë¸ ë¡œë“œ

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

base_model = "Qwen/Qwen2.5-3B-Instruct"
adapter_path = "lora-output-jason-mom"

tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(base_model)
model = PeftModel.from_pretrained(model, adapter_path)
```

### ìƒ˜í”Œ ì¶”ë¡ 

```python
prompt = "<SYS> ... <CTX> ... </CTX> <PLAYER>ì €ê¸°ìš”, Jasonì„ ì•„ì‹œë‚˜ìš”?\n<NPC>"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=200)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

---
## ğŸ“½ ì‹œì—° ì˜ìƒ

(ì—…ë°ì´íŠ¸ ì˜ˆì •)
---

## ğŸ–¥ í•™ìŠµ í™˜ê²½

* **GPU:** NVIDIA A100 / Colab GPU
* **Framework:** PyTorch + HuggingFace Transformers
* **Fine-Tuning:** QLoRA (LoRA Adapter)
* **Batch Size:** 16 (Gradient Accumulation ì‚¬ìš©)
* **Epochs:** 3
* **Loss êµ¬ì„±:** LM + Delta(MSE) + Flag(BCE)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì„±ê³¼

* NPC ì‹ ë¢°ë„, ê´€ê³„ ìƒíƒœ, í€˜ìŠ¤íŠ¸ ì´ë²¤íŠ¸ ë°˜ì˜ ëŒ€í™” ê°€ëŠ¥
* QLoRA ê¸°ë°˜ 4bit Adapter í•™ìŠµìœ¼ë¡œ íš¨ìœ¨ì  í•™ìŠµ ë° ë°°í¬
* Delta/Flag í—¤ë“œë¡œ ê²Œì„ ë‚´ ì´ë²¤íŠ¸ ë° ìƒíƒœ ë³€í™”ë¥¼ ë™ì‹œì— ì²˜ë¦¬
* í¬íŠ¸í´ë¦¬ì˜¤ìš© ë°ëª¨ ì œê³µ ê°€ëŠ¥

---

## ğŸ“ í¬íŠ¸í´ë¦¬ì˜¤ ì—°ê³„

* **FPS Game í”„ë¡œì íŠ¸:** ê²Œì„ ë‚´ ìºë¦­í„° AIì™€ ì—°ë™, ì´ë²¤íŠ¸ ë°œìƒ í…ŒìŠ¤íŠ¸
* **Persona Chat Engine:** ëŒ€í™” ê¸°ë°˜ ìŠ¤í† ë¦¬ ì „ê°œ, ë©€í‹° NPC ê´€ë¦¬
* ì´ ë‘ í”„ë¡œì íŠ¸ëŠ” í†µí•©ì ìœ¼ë¡œ í”Œë ˆì´ì–´ ê²½í—˜ ì„¤ê³„ì™€ AI NPC êµ¬í˜„ ëŠ¥ë ¥ì„ ê°•ì¡°

---

## ğŸ”— ê´€ë ¨ ë§í¬

* [Portfolio](https://www.github.com/m97j/portfolio)
* [FPS Game](https://github.com/m97j/fpsgame)
* [Persona Chat Engine](https://github.com/m97j/persona-chat-engine)

---




